{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "539a33a6",
   "metadata": {},
   "source": [
    "# Реализация DEFLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1192d1",
   "metadata": {},
   "source": [
    "## Импорт текста и декапитализированного варианта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6631c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'text.txt'\n",
    "with open(filename, 'r', encoding='ASCII') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cfc55e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('decapitalized.txt', 'r', encoding='ASCII') as f:\n",
    "    decapitalized_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfba073",
   "metadata": {},
   "source": [
    "### Статическое дерево Хаффмана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c375251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def huffman(frequencies: dict) -> list:\n",
    "    \"\"\"Создание статического дерева Хаффмана на основе словаря частот\n",
    "\n",
    "    Пример логики работы:  \n",
    "    frequencies = {'a': 10, 'b': 3, 'c': 2}  \n",
    "    queue = [(2, 'c'), (3, 'b'), (10, 'a')]  \n",
    "    res = {'a': '', 'b': '', 'c': ''}  \n",
    "\n",
    "    1 шаг:  \n",
    "    first_freq, first_letters = 2, 'c',  \n",
    "    second_freq, second_letters = 3, 'b'  \n",
    "      \n",
    "    res = {'a': '', 'b': '1', 'c': '0'}  \n",
    "    queue = [(5, 'cb'), (10, 'a')]  \n",
    "  \n",
    "    2 шаг:  \n",
    "    first_freq, first_letters = 5, 'cb',  \n",
    "    second_freq, second_letters = 10, 'a'  \n",
    "      \n",
    "    res = {'a': '1', 'b': '01', 'c': '00'}  \n",
    "    queue = [(15, 'cba')]  \n",
    "  \n",
    "    Общий смысл - сопоставить наиболее редким символам наиболее длинный код  \n",
    "    и, наоборот, наиболее частым - наиболее короткий  \n",
    "    \"\"\"\n",
    "\n",
    "    # Для текста с алфавитом из одного символа кодируем его нулём\n",
    "    if len(frequencies) == 1:\n",
    "        letter, = frequencies\n",
    "        return {letter: '0'}\n",
    "\n",
    "    # инициализируем очередь, которая будет содержать в начале символы с минимальной частотой (мин-куча)\n",
    "    queue = []\n",
    "    res = {letter: '' for letter in frequencies} # инициализируем код для каждой частоты\n",
    "\n",
    "    for letter, frequency in frequencies.items():\n",
    "        heappush(queue, (frequency, letter)) # делаем мин-кучу из пустого списка\n",
    "\n",
    "    while len(queue) > 1:\n",
    "        first_freq, first_letters = heappop(queue) # достаём самый редкий символ из кучи и его частоту, удаляя из кучи\n",
    "        second_freq, second_letters = heappop(queue) # достаём второй самый редкий символ из кучи и его частоту, удаляя из кучи\n",
    "\n",
    "        for letter in first_letters:\n",
    "            res[letter] = '0' + res[letter] # для самого редкого элемента прибавляем ноль в начало кода для каждого символа, из которого он состоит\n",
    "\n",
    "        # Пример: для first_letters = 'abc' прибавится 0 в начало кода для a, b, c.\n",
    "\n",
    "        for letter in second_letters:\n",
    "            res[letter] = '1' + res[letter] # для второго самого редкого элемента прибавляем единицу в начале кода для каждого символа, из которого он состоит\n",
    "\n",
    "\n",
    "        # Закидываем в мин-кучу объединённый элемент из прошлых двух: сумма их частот и сумма их названий ('a': 3, 'b':4 => (7, 'ab'))\n",
    "        heappush(\n",
    "            queue,\n",
    "            (\n",
    "                first_freq + second_freq,\n",
    "                ''.join(sorted(first_letters + second_letters))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return res\n",
    "\n",
    "def count_tree_lenght(tree: dict) -> int:\n",
    "    # Кодируем каждый символ одним байтом, \n",
    "    return len(tree.keys()) * 8 + len(tree.values()) * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbeb31d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': '1011', 'b': '10101', 'c': '10100', 'd': '11', 'f': '100', 'k': '0'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = {'a': 10, 'b': 3, 'c': 2, 'd': 32, 'f': 13, 'k': 44}\n",
    "huffman(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed1e46",
   "metadata": {},
   "source": [
    "## Кодировщики "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb240ffd",
   "metadata": {},
   "source": [
    "### Енкодер букв и длин в единый алфавит, который будет использоваться для построения первого дерева Хаффмана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fb7e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_codes = [\n",
    "    (3, 0),     # 257\n",
    "    (4, 0),     # 258\n",
    "    (5, 0),     # 259\n",
    "    (6, 0),     # 260\n",
    "    (7, 0),     # 261\n",
    "    (8, 0),     # 262\n",
    "    (9, 0),     # 263\n",
    "    (10, 0),    # 264\n",
    "    (11, 1),    # 265 (11-12)\n",
    "    (13, 1),    # 266 (13-14)\n",
    "    (15, 1),    # 267 (15-16)\n",
    "    (17, 1),    # 268 (17-18)\n",
    "    (19, 2),    # 269 (19-22)\n",
    "    (23, 2),    # 270 (23-26)\n",
    "    (27, 2),    # 271 (27-30)\n",
    "    (31, 2),    # 272 (31-34)\n",
    "    (35, 3),    # 273 (35-42)\n",
    "    (43, 3),    # 274 (43-50)\n",
    "    (51, 3),    # 275 (51-58)\n",
    "    (59, 3),    # 276 (59-66)\n",
    "    (67, 4),    # 277 (67-82)\n",
    "    (83, 4),    # 278 (83-98)\n",
    "    (99, 4),    # 279 (99-114)\n",
    "    (115, 4),   # 280 (115-130)\n",
    "    (131, 5),   # 281 (131-162)\n",
    "    (163, 5),   # 282 (163-194)\n",
    "    (195, 5),   # 283 (195-226)\n",
    "    (227, 5),   # 284 (227-257)\n",
    "    (258, 0)    # 285\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_symbol(symbol, length_codes):\n",
    "    \"\"\"Кодирует символ (букву или длину) в соответствующий код.\"\"\"\n",
    "    if isinstance(symbol, str):\n",
    "        return ord(symbol)\n",
    "    \n",
    "    elif isinstance(symbol, int):\n",
    "        if not 3 <= symbol <= 258:\n",
    "            raise ValueError(\"Length must be in 3-258 range\")\n",
    "        \n",
    "        for i in range(len(length_codes)):\n",
    "            # Проверяем верхнюю границу (если не последний элемент)\n",
    "            if i < len(length_codes) - 1 and symbol >= length_codes[i+1][0]:\n",
    "                continue\n",
    "            \n",
    "            difference = symbol - length_codes[i][0]\n",
    "            return (257 + i, bin(difference)[2:])\n",
    "    \n",
    "    else:\n",
    "        raise TypeError(\"Symbol must be str (letter) or int (length)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e72de5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(285, '0')\n"
     ]
    }
   ],
   "source": [
    "print(encode_symbol(258, length_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "20f110bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(ord('\\n'))\n",
    "print(encode_symbol('\\n', length_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ba879",
   "metadata": {},
   "source": [
    "### Енкодер смещений, который будет использоваться для построения второго дерева Хаффмана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "697b8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_codes = [\n",
    "    (1, 0),       # код 0\n",
    "    (2, 0),       # код 1\n",
    "    (3, 0),       # код 2\n",
    "    (4, 0),       # код 3\n",
    "    (5, 1),       # код 4 (5-6)\n",
    "    (7, 1),       # код 5 (7-8)\n",
    "    (9, 2),       # код 6 (9-12)\n",
    "    (13, 2),      # код 7 (13-16)\n",
    "    (17, 3),      # код 8 (17-24)\n",
    "    (25, 3),      # код 9 (25-32)\n",
    "    (33, 4),      # код 10 (33-48)\n",
    "    (49, 4),      # код 11 (49-64)\n",
    "    (65, 5),      # код 12 (65-96)\n",
    "    (97, 5),      # код 13 (97-128)\n",
    "    (129, 6),     # код 14 (129-192)\n",
    "    (193, 6),     # код 15 (193-256)\n",
    "    (257, 7),     # код 16 (257-384)\n",
    "    (385, 7),     # код 17 (385-512)\n",
    "    (513, 8),     # код 18 (513-768)\n",
    "    (769, 8),     # код 19 (769-1024)\n",
    "    (1025, 9),    # код 20 (1025-1536)\n",
    "    (1537, 9),    # код 21 (1537-2048)\n",
    "    (2049, 10),   # код 22 (2049-3072)\n",
    "    (3073, 10),   # код 23 (3073-4096)\n",
    "    (4097, 11),   # код 24 (4097-6144)\n",
    "    (6145, 11),   # код 25 (6145-8192)\n",
    "    (8193, 12),   # код 26 (8193-12288)\n",
    "    (12289, 12),  # код 27 (12289-16384)\n",
    "    (16385, 13),  # код 28 (16385-24576)\n",
    "    (24577, 13),  # код 29 (24577-32768)\n",
    "    (32769, 14),  # код 30 (32769-49152) (Расширили для случая 64кб длины окна)\n",
    "    (49153, 14),  # код 31 (49153-65536) (Расширили для случая 64кб длины окна)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f21aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_distance(distance: int, distance_codes: list) -> tuple:\n",
    "    for i in range(len(distance_codes)):\n",
    "        # Проверяем верхнюю границу (если не последний элемент)\n",
    "        if i < len(distance_codes) - 1 and distance >= distance_codes[i+1][0]:\n",
    "            continue\n",
    "        \n",
    "        difference = distance - distance_codes[i][0]\n",
    "        return (i, bin(difference)[2:].zfill(distance_codes[i][1]))\n",
    "    \n",
    "    raise ValueError(f\"Invalid distance: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e73b7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, '00000000000001')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_distance(49154, distance_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc285c9a",
   "metadata": {},
   "source": [
    "## LZ77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eabe5d8",
   "metadata": {},
   "source": [
    "### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7cde7f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lz77Compressor:\n",
    "    def __init__(self, window_size: int, data, min_match_len=3, max_match_len=258):\n",
    "        if window_size > 0 and window_size <= 64 * 1024:\n",
    "            self.window_size = window_size\n",
    "        else:\n",
    "            raise ValueError('Неверно указана ширина окна. Возможные значения: от 1 до 64кб')\n",
    "        \n",
    "        self.data = data\n",
    "        self.min_match_len = min_match_len\n",
    "        self.max_match_len = max_match_len\n",
    "        self.hash_table = {}  # ключ: 3-символьная строка, значение: список позиций\n",
    "\n",
    "    def compress(self):\n",
    "        pos = 0\n",
    "        output = []\n",
    "        \n",
    "        while pos < len(self.data):\n",
    "            # Определяем границы текущего буфера\n",
    "            buffer_start = max(0, pos - self.window_size)\n",
    "            \n",
    "            # Получаем текущий префикс (3 символа)\n",
    "            if pos + 3 > len(self.data):\n",
    "                output.append(self.data[pos])\n",
    "                pos += 1\n",
    "                continue\n",
    "                \n",
    "            prefix = self.data[pos:pos+3]\n",
    "            \n",
    "            # Ищем совпадения в хэш-таблице\n",
    "            match_offset, match_len = self._find_longest_match(pos, buffer_start)\n",
    "            \n",
    "            if match_len >= self.min_match_len:\n",
    "                output.append((match_offset, match_len))\n",
    "                # Добавляем в хэш-таблицу все новые 3-символьные подстроки из найденной фразы\n",
    "                for i in range(pos, pos + match_len):\n",
    "                    if i + 3 <= len(self.data):\n",
    "                        new_prefix = self.data[i:i+3]\n",
    "                        self.hash_table.setdefault(new_prefix, []).append(i)\n",
    "                pos += match_len\n",
    "            else:\n",
    "                output.append(self.data[pos])\n",
    "                # Добавляем текущий префикс в хэш-таблицу\n",
    "                self.hash_table.setdefault(prefix, []).append(pos)\n",
    "                pos += 1\n",
    "                \n",
    "        return output\n",
    "\n",
    "    def _find_longest_match(self, pos, buffer_start):\n",
    "        max_len = 0\n",
    "        max_offset = 0\n",
    "        \n",
    "        if pos + 3 > len(self.data):\n",
    "            return 0, 0\n",
    "            \n",
    "        prefix = self.data[pos:pos+3]\n",
    "        candidates = self.hash_table.get(prefix, [])\n",
    "        \n",
    "        for candidate_pos in reversed(candidates):\n",
    "            # Пропускаем кандидатов вне текущего буфера\n",
    "            if candidate_pos < buffer_start:\n",
    "                break\n",
    "                \n",
    "            offset = pos - candidate_pos\n",
    "            length = 3  # уже знаем, что первые 3 символа совпадают\n",
    "            \n",
    "            # Сравниваем остальные символы\n",
    "            max_possible = min(self.max_match_len, len(self.data) - pos)\n",
    "            while (length < max_possible and \n",
    "                   self.data[candidate_pos + length] == self.data[pos + length]):\n",
    "                length += 1\n",
    "                \n",
    "            if length > max_len:\n",
    "                max_len = length\n",
    "                max_offset = offset\n",
    "                \n",
    "        return max_offset, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7800e390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', (1, 37), '1', '7', '8', '1', '\\n', '\\n', (32, 26), 'T', 'H', 'E', ' ', 'C', 'R', 'I', 'T', 'I', 'Q', 'U', 'E', ' ', 'O', 'F', ' ', 'P', 'U', 'R', 'E', ' ', 'R', 'E', 'A', 'S', 'O', 'N', (55, 28), (1, 6), 'b', 'y', ' ', 'I', 'm', 'm', 'a', 'n', 'u', 'e', 'l', ' ', 'K', 'a', 'n', 't', (50, 25), 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'e', 'd', (52, 4), 'J', '.', ' ', 'M', '.', ' ', 'D', (6, 3), 'e', 'i', 'k', 'l', 'e', 'j', 'o', 'h', 'n', (58, 14), 'P', 'R', 'E', 'F', 'A', 'C', 'E', ' ', 'T', 'O', (160, 5), 'F', 'I', 'R', 'S', 'T']\n"
     ]
    }
   ],
   "source": [
    "data = text\n",
    "compressor = Lz77Compressor(window_size=32 * 1024, data=data)\n",
    "result = compressor.compress()\n",
    "print(result[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e81acf1",
   "metadata": {},
   "source": [
    "### Version 2 (+ Трюк с улучшением поиска)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd72d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lz77Compressor_Tricked:\n",
    "    def __init__(self, window_size: int, data, min_match_len=3, max_match_len=258):\n",
    "        if 0 < window_size <= 64 * 1024:\n",
    "            self.window_size = window_size\n",
    "        else:\n",
    "            raise ValueError('Неверно указана ширина окна. Возможные значения: от 1 до 64КБ')\n",
    "        \n",
    "        self.data = data\n",
    "        self.min_match_len = min_match_len\n",
    "        self.max_match_len = max_match_len\n",
    "        self.hash_table = {}  # ключ: 3-символьная строка, значение: список позиций\n",
    "\n",
    "    def compress(self):\n",
    "        pos = 0\n",
    "        output = []\n",
    "        \n",
    "        while pos < len(self.data):\n",
    "            buffer_start = max(0, pos - self.window_size)\n",
    "            \n",
    "            if pos + self.min_match_len > len(self.data):\n",
    "                output.append(self.data[pos])\n",
    "                pos += 1\n",
    "                continue\n",
    "\n",
    "            prefix = self.data[pos:pos+self.min_match_len]\n",
    "            match_offset, match_len = self._find_longest_match(pos, buffer_start)\n",
    "\n",
    "            # Если найден повтор, делаем повтор снова, начиная со следующей позиции\n",
    "            if match_len >= self.min_match_len:\n",
    "                lookahead_better = False\n",
    "                if pos + 1 + self.min_match_len <= len(self.data):\n",
    "                    next_prefix = self.data[pos+1: pos+1+self.min_match_len]\n",
    "                    if next_prefix in self.hash_table:\n",
    "                        next_offset, next_len = self._find_longest_match(pos + 1, buffer_start)\n",
    "                        # Если найден более длинный повтор, начиная со след. позиции, записываем литерал и более длинный повтор\n",
    "                        if next_len > match_len: # Здесь можно добавить порог (next_len > match_len + 5)\n",
    "                            output.append(self.data[pos])  # Записываем одинокий литерал\n",
    "                            self._add_prefix(pos)\n",
    "                            pos += 1\n",
    "                            output.append((pos - next_offset, next_len)) # Записываем новый более длинный повтор\n",
    "                            self._add_match_to_table(pos, next_len)\n",
    "                            pos += next_len\n",
    "                            lookahead_better = True\n",
    "                \n",
    "                # Если трюк не дал результат лучше, добавляем имеющиеся данные\n",
    "                if not lookahead_better:\n",
    "                    output.append((match_offset, match_len))\n",
    "                    self._add_match_to_table(pos, match_len)\n",
    "                    pos += match_len\n",
    "            else:\n",
    "                output.append(self.data[pos])\n",
    "                self._add_prefix(pos)\n",
    "                pos += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _find_longest_match(self, pos, buffer_start):\n",
    "        max_len = 0\n",
    "        max_offset = 0\n",
    "\n",
    "        if pos + self.min_match_len > len(self.data):\n",
    "            return 0, 0\n",
    "\n",
    "        prefix = self.data[pos:pos+self.min_match_len]\n",
    "        candidates = self.hash_table.get(prefix, [])\n",
    "\n",
    "        for candidate_pos in reversed(candidates):\n",
    "            if candidate_pos < buffer_start:\n",
    "                break\n",
    "\n",
    "            offset = pos - candidate_pos\n",
    "            length = self.min_match_len\n",
    "            max_possible = min(self.max_match_len, len(self.data) - pos)\n",
    "\n",
    "            while (length < max_possible and\n",
    "                   self.data[pos + length] == self.data[candidate_pos + length]):\n",
    "                length += 1\n",
    "\n",
    "            if length > max_len:\n",
    "                max_len = length\n",
    "                max_offset = offset\n",
    "\n",
    "        return max_offset, max_len\n",
    "\n",
    "    def _add_prefix(self, pos):\n",
    "        \"\"\"Добавить текущий 3-символьный префикс в хэш-таблицу\"\"\"\n",
    "        if pos + self.min_match_len <= len(self.data):\n",
    "            prefix = self.data[pos:pos+self.min_match_len]\n",
    "            self.hash_table.setdefault(prefix, []).append(pos)\n",
    "\n",
    "    def _add_match_to_table(self, pos, match_len):\n",
    "        \"\"\"Добавить все 3-символьные подстроки фразы в таблицу\"\"\"\n",
    "        for i in range(pos, pos + match_len):\n",
    "            if i + self.min_match_len <= len(self.data):\n",
    "                prefix = self.data[i:i+self.min_match_len]\n",
    "                self.hash_table.setdefault(prefix, []).append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "99a6d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', (1, 37), '1', '7', '8', '1', '\\n', '\\n', (32, 26), 'T', 'H', 'E', ' ', 'C', 'R', 'I', 'T', 'I', 'Q', 'U', 'E', ' ', 'O', 'F', ' ', 'P', 'U', 'R', 'E', ' ', 'R', 'E', 'A', 'S', 'O', 'N', (55, 28), (1, 6), 'b', 'y', ' ', 'I', 'm', 'm', 'a', 'n', 'u', 'e', 'l', ' ', 'K', 'a', 'n', 't', (50, 25), 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'e', 'd', (52, 4), 'J', '.', ' ', 'M', '.', ' ', 'D', (6, 3), 'e', 'i', 'k', 'l', 'e', 'j', 'o', 'h', 'n', (58, 14), 'P', 'R', 'E', 'F', 'A', 'C', 'E', ' ', 'T', 'O', (160, 5), 'F', 'I', 'R', 'S', 'T']\n"
     ]
    }
   ],
   "source": [
    "data = text\n",
    "compressor = Lz77Compressor_Tricked(window_size=64 * 1024, data=data)\n",
    "result = compressor.compress()\n",
    "print(result[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03296034",
   "metadata": {},
   "source": [
    "## Разбиение результата на последовательности символов/длин и смещений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1dc528ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "literals_or_lengths = []\n",
    "distances = []\n",
    "\n",
    "for entry in result:\n",
    "    if isinstance(entry, tuple):\n",
    "        offset, length = entry\n",
    "        literals_or_lengths.append(length)\n",
    "        distances.append(offset)\n",
    "    else:\n",
    "        literals_or_lengths.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ae2e2b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список литералов или длин: [' ', 37, '1', '7', '8', '1', '\\n', '\\n', 26, 'T'], его длина = 168938\n",
      "Список расстояний: [1, 32, 55, 1, 50, 52, 6, 58, 160, 166], его длина = 136680\n"
     ]
    }
   ],
   "source": [
    "print(f'Список литералов или длин: {literals_or_lengths[:10]}, его длина = {len(literals_or_lengths)}')\n",
    "print(f'Список расстояний: {distances[:10]}, его длина = {len(distances)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09de80",
   "metadata": {},
   "source": [
    "## Кодируем полученные последовательности и считаем частоты кодов для передачи в статические деревья Хаффмана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "17c9d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_frequencies = Counter()\n",
    "distance_frequencies = Counter()\n",
    "\n",
    "for entry in result:  # result — исходный список LZ77 (литералы/кортежи)\n",
    "    if isinstance(entry, tuple):\n",
    "        offset, length = entry\n",
    "        \n",
    "        # Кодируем длину и добавляем в symbol_frequencies\n",
    "        code, _ = encode_symbol(length, length_codes)\n",
    "        symbol_frequencies[code] += 1\n",
    "\n",
    "        # Кодируем расстояние и добавляем в distance_frequencies\n",
    "        dist_code, _ = encode_distance(offset, distance_codes)\n",
    "        distance_frequencies[dist_code] += 1\n",
    "            \n",
    "    else:\n",
    "        # Кодируем литерал\n",
    "        code = encode_symbol(entry, length_codes)\n",
    "        symbol_frequencies[code] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a955f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([32, 273, 49, 55, 56, 10, 270, 84, 72, 69, 67, 82, 73, 81, 85, 79, 70, 80, 65, 83, 78, 271, 260, 98, 121, 109, 97, 110, 117, 101, 108, 75, 116, 114, 115, 100, 258, 74, 46, 77, 68, 257, 105, 107, 106, 111, 104, 266, 259, 44, 263, 112, 102, 99, 103, 113, 119, 268, 264, 118, 262, 261, 120, 87, 265, 66, 59, 45, 58, 269, 42, 91, 34, 93, 122, 76, 267, 40, 41, 39, 63, 53, 50, 71, 272, 86, 61, 88, 43, 62, 51, 89, 52, 274, 54, 57, 48, 275, 278, 276, 90, 125, 33])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(symbol_frequencies.keys())\n",
    "len(symbol_frequencies.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd57e84",
   "metadata": {},
   "source": [
    "## Деревья Хаффмана"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4957df18",
   "metadata": {},
   "source": [
    "Перепишем логику построения деревьев Хаффмана для случая подачи кодов на вход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ba5a3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop\n",
    "\n",
    "def huffman(frequencies: dict) -> dict:\n",
    "    \"\"\"Создание дерева Хаффмана для числовых символов\"\"\"\n",
    "\n",
    "    if len(frequencies) == 1:\n",
    "        only_symbol = next(iter(frequencies))\n",
    "        return {only_symbol: '0'}\n",
    "\n",
    "    queue = []\n",
    "    res = {symbol: '' for symbol in frequencies}\n",
    "\n",
    "    for symbol, freq in frequencies.items():\n",
    "        heappush(queue, (freq, [symbol]))  # список из одного символа (тут изменение symbol -> [symbol])\n",
    "\n",
    "    while len(queue) > 1:\n",
    "        freq1, symbols1 = heappop(queue) # например: 50, 32\n",
    "        freq2, symbols2 = heappop(queue) # например: 40, 64\n",
    "\n",
    "        for sym in symbols1:\n",
    "            res[sym] = '0' + res[sym]\n",
    "        for sym in symbols2:\n",
    "            res[sym] = '1' + res[sym]\n",
    "\n",
    "        merged_symbols = symbols1 + symbols2 # Получается список из объединённых кодов символов, например: [32, 64]. Затем уже для каждого кода из списка будет добавляться 0 или 1\n",
    "        heappush(queue, (freq1 + freq2, merged_symbols)) #(тут изменение. Пушим не конкатенацию строк, а объединённый список)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f87d5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_huffman_codes = huffman(symbol_frequencies)\n",
    "distance_huffman_codes = huffman(distance_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "29f595ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def compress_data(literals_or_lengths, distances, \n",
    "                 length_codes, distance_codes,\n",
    "                 encode_symbol, encode_distance,\n",
    "                 symbol_huffman_codes, distance_huffman_codes):\n",
    "    \"\"\"\n",
    "    Финальный этап компрессии с битовой записью\n",
    "    \n",
    "    Параметры:\n",
    "        literals_or_lengths: список литералов (str) и длин (int)\n",
    "        distances: список расстояний (только для кортежей)\n",
    "        length_codes: таблица кодирования длин\n",
    "        distance_codes: таблица кодирования расстояний\n",
    "        encode_symbol: функция кодирования символа/длины\n",
    "        encode_distance: функция кодирования расстояния\n",
    "        symbol_huffman_codes: готовые коды Хаффмана для символов/длин\n",
    "        distance_huffman_codes: готовые коды Хаффмана для расстояний\n",
    "    \"\"\"\n",
    "    \n",
    "    class BitWriter:\n",
    "        def __init__(self):\n",
    "            self.buffer = 0      # Бит-буфер\n",
    "            self.bit_count = 0   # Текущее количество бит в буфере\n",
    "            self.output = bytearray()\n",
    "\n",
    "        def write_bits(self, value, num_bits):\n",
    "            \"\"\"Запись битов в буфер\"\"\"\n",
    "            self.buffer = (self.buffer << num_bits) | value\n",
    "            self.bit_count += num_bits\n",
    "            while self.bit_count >= 8:\n",
    "                self.output.append((self.buffer >> (self.bit_count - 8)) & 0xFF)\n",
    "                self.bit_count -= 8\n",
    "                self.buffer &= (1 << self.bit_count) - 1\n",
    "\n",
    "        def flush(self):\n",
    "            \"\"\"Завершаем запись (дополняем нулями)\"\"\"\n",
    "            if self.bit_count > 0:\n",
    "                self.output.append((self.buffer << (8 - self.bit_count)) & 0xFF)\n",
    "            return bytes(self.output)\n",
    "\n",
    "    writer = BitWriter()\n",
    "    dist_index = 0  # Индекс в массиве расстояний, чтобы записывать код расстояния сразу после записи кода длины\n",
    "\n",
    "    for item in literals_or_lengths:\n",
    "        if isinstance(item, int): # Встретили число => кодируем длину и расстояние (смещение)\n",
    "            # Кодируем длину\n",
    "            code, extra_bits = encode_symbol(item, length_codes)\n",
    "            # Получаем код из дерева Хаффмана для полученного кода длины и записываем его\n",
    "            huff_code = symbol_huffman_codes[code]\n",
    "            writer.write_bits(int(huff_code, 2), len(huff_code))\n",
    "            \n",
    "            # Записываем дополнительные биты длины, если есть\n",
    "            if extra_bits:\n",
    "                writer.write_bits(int(extra_bits, 2), len(extra_bits))\n",
    "\n",
    "            # Кодируем расстояние\n",
    "            dist = distances[dist_index]\n",
    "            dist_code, dist_extra = encode_distance(dist, distance_codes)\n",
    "            # Получаем код из дерева Хаффмана для полученного кода смещения и записываем его\n",
    "            dist_huff = distance_huffman_codes[dist_code]\n",
    "            writer.write_bits(int(dist_huff, 2), len(dist_huff))\n",
    "            \n",
    "            # Записываем дополнительные биты расстояния\n",
    "            if dist_extra:\n",
    "                writer.write_bits(int(dist_extra, 2), len(dist_extra))\n",
    "            \n",
    "            dist_index += 1\n",
    "\n",
    "        else:  # Литерал\n",
    "            code = encode_symbol(item, length_codes)\n",
    "            huff_code = symbol_huffman_codes[code]\n",
    "            writer.write_bits(int(huff_code, 2), len(huff_code))\n",
    "\n",
    "    return writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "20815633",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_data = compress_data(\n",
    "    literals_or_lengths=literals_or_lengths,\n",
    "    distances=distances,\n",
    "    length_codes=length_codes,\n",
    "    distance_codes=distance_codes,\n",
    "    encode_symbol=encode_symbol,\n",
    "    encode_distance=encode_distance,\n",
    "    symbol_huffman_codes=symbol_huffman_codes,\n",
    "    distance_huffman_codes=distance_huffman_codes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8feb2026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер сжатого текста = 388.35 кб\n"
     ]
    }
   ],
   "source": [
    "print(f'Размер сжатого текста = {len(compressed_data) / 1024:.2f} кб')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620dd87",
   "metadata": {},
   "source": [
    "## Сбор всего вместе и анализ влияния параметров на скорость и степень сжатия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "328a8802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deflate_compressor(data, compressor='usual', window_size=32*1024):\n",
    "    if compressor == 'usual':\n",
    "        compressor = Lz77Compressor(window_size=window_size, data=data)\n",
    "    elif compressor == 'tricked':\n",
    "        compressor = Lz77Compressor_Tricked(window_size=window_size, data=data)\n",
    "    else:\n",
    "        raise ValueError('Выберите компрессор: usual или tricked')\n",
    "    \n",
    "    result = compressor.compress()  # список литералов и кортежей (offset, length)\n",
    "\n",
    "    # 2. Подготавливаем списки для дальнейшего кодирования\n",
    "    literals_or_lengths = []\n",
    "    distances = []\n",
    "\n",
    "    for entry in result:\n",
    "        if isinstance(entry, tuple):\n",
    "            offset, length = entry\n",
    "            literals_or_lengths.append(length)  # длина фразы\n",
    "            distances.append(offset)            # смещение\n",
    "        else:\n",
    "            literals_or_lengths.append(entry)   # литерал (символ)\n",
    "\n",
    "    # 3. Подсчитываем частоты кодов для Хаффмана\n",
    "    symbol_frequencies = Counter()\n",
    "    distance_frequencies = Counter()\n",
    "\n",
    "    for entry in result:\n",
    "        if isinstance(entry, tuple):\n",
    "            offset, length = entry\n",
    "\n",
    "            # Кодируем длину и увеличиваем частоту символа\n",
    "            code, _ = encode_symbol(length, length_codes)\n",
    "            symbol_frequencies[code] += 1\n",
    "\n",
    "            # Кодируем расстояние и увеличиваем частоту\n",
    "            dist_code, _ = encode_distance(offset, distance_codes)\n",
    "            distance_frequencies[dist_code] += 1\n",
    "        else:\n",
    "            # Литерал — кодируем напрямую\n",
    "            code = encode_symbol(entry, length_codes)\n",
    "            symbol_frequencies[code] += 1\n",
    "\n",
    "    # 4. Строим таблицы кодов Хаффмана для длины и расстояния\n",
    "    symbol_huffman_codes = huffman(symbol_frequencies)\n",
    "    distance_huffman_codes = huffman(distance_frequencies)\n",
    "\n",
    "    # 5. Генерируем окончательный сжатый поток\n",
    "    compressed_data = compress_data(\n",
    "        literals_or_lengths=literals_or_lengths,\n",
    "        distances=distances,\n",
    "        length_codes=length_codes,\n",
    "        distance_codes=distance_codes,\n",
    "        encode_symbol=encode_symbol,\n",
    "        encode_distance=encode_distance,\n",
    "        symbol_huffman_codes=symbol_huffman_codes,\n",
    "        distance_huffman_codes=distance_huffman_codes\n",
    "    )\n",
    "\n",
    "    return compressed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "298178c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для обычного текста:\n",
      "                     usual                  tricked\n",
      "32  400.85 кб, 5.43 секунд   415.72 кб, 7.91 секунд\n",
      "64  382.10 кб, 7.81 секунд  388.35 кб, 14.16 секунд \n",
      "\n",
      "Для декапитализированного текста:\n",
      "                     usual                  tricked\n",
      "32  395.53 кб, 5.31 секунд   409.80 кб, 8.10 секунд\n",
      "64  377.09 кб, 7.90 секунд  382.86 кб, 13.61 секунд \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time as time\n",
    "import pandas as pd\n",
    "\n",
    "for data in [text, decapitalized_text]:\n",
    "    df = pd.DataFrame(columns = ['usual', 'tricked'], index=[32, 64])\n",
    "    for compressor in ['usual', 'tricked']:\n",
    "        for window_size in [32*1024, 64*1024]:\n",
    "            start_time = time.time()\n",
    "            size = len(deflate_compressor(data=data, compressor=compressor, window_size=window_size)) / 1024\n",
    "            required_time = time.time() - start_time\n",
    "\n",
    "            df.loc[window_size/1024, compressor] = f'{size:.2f} кб, {required_time:.2f} секунд'\n",
    "    \n",
    "    print(f'Для {'декапитализированного' if data == decapitalized_text else 'обычного'} текста:')\n",
    "    print(df, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e5f77",
   "metadata": {},
   "source": [
    "Выводы:  \n",
    "1. Увеличение размера окна позволяет улучшить степень сжатия, но при этом увеличивается время сжатия, но не линейно  \n",
    "  \n",
    "2. Использование трюка для улучшения качества сжатия не принесло, но уменьшило скорость сжатия из-за отсутствия параллельного вычислений для T[n..] и T[n+1..]    \n",
    "При этом, если добавить условие, что длина нового повтора должна быть на 5 меньше (а не просто меньше), чем старого, то степень сжатия незначительного улучшается (на 1кб)  \n",
    "  \n",
    "3. В ДЗ 2.1 было выяснено, что запись исключений в сжатом виде занимает 2.152 кб.  \n",
    "При этом разница между объёмом обычного и декапитализированного сжатого текста составляет примерно 5кб в каждом случае,   \n",
    "то есть декапитализация позволит сэкономить 3кб (0,24% от исходного текста в 1239кб), следовательно формально оправдана\n",
    "\n",
    "4. Время сжатия декапитализированного и исходного текстов одинаковое"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef1402",
   "metadata": {},
   "source": [
    "# Для сравнения библиотечная реализация deflate в zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "77869ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed original: 374.21 kb\n",
      "Compressed decapitalized: 368.31 kb\n"
     ]
    }
   ],
   "source": [
    "import zlib\n",
    "\n",
    "def lz77_compress(data):\n",
    "    \"\"\"Сжатие данных с использованием zlib (LZ77 + Huffman)\"\"\"\n",
    "    return zlib.compress(data, level=zlib.Z_BEST_COMPRESSION)\n",
    "\n",
    "\n",
    "original_data = text.encode('ascii')\n",
    "compressed = lz77_compress(original_data)\n",
    "print(f\"Compressed original: {len(compressed) / 1024:.2f} kb\")\n",
    "\n",
    "decapitalized_data = decapitalized_text.encode('ascii')\n",
    "compressed = lz77_compress(decapitalized_data)\n",
    "print(f\"Compressed decapitalized: {len(compressed) / 1024:.2f} kb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
